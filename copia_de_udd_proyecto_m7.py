# -*- coding: utf-8 -*-
"""Copia de UDD_Proyecto M7

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o_GSmWk5skCgZ3KwXZf-xOFVEoHQOGfk

## **Bootcamp: Ciencia de Datos e Inteligencia Artificial**
## **Proyecto del Módulo 7: Técnicas avanzadas para ciencia de datos y empleabilidad**

Hola, ya es el último proyecto, has avanzado y aprendido mucho hasta acá. ¡Muchas felicidades!

Es hora de poner en práctica todo lo que hemos aprendido a lo largo de nuestra travesía.

Lee el proyecto y revisa con cuidado cada una de las instrucciones. Procura plasmar todo tu potencial para que lo concluyas de manera sobresaliente.

¡Éxito!

# Objetivos
- Aplicar con éxito todos los conocimientos que has adquirido a lo largo del Bootcamp.
- Consolidar las técnicas de limpieza, entrenamiento, graficación y ajuste a modelos de *Machine Learning*.
- Generar una API que brinde predicciones como resultado a partir de datos enviados.

# Proyecto

1. Selecciona uno de los siguientes *datasets*:
  - Imágenes de rayos X de pecho para detectar neumonía: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia

  *redes neuronales convolucionales (es el mas sencillo de los 4 dataset)



  - *Reviews* de aplicaciones de la Google Play Store: https://www.kaggle.com/datasets/lava18/google-play-store-apps


  - Estadísticas demográficas de los ganadores del premio Oscar de la Academia: https://www.kaggle.com/datasets/fmejia21/demographics-of-academy-awards-oscars-winners


  - Aspiraciones profesionales de la generación Z: https://www.kaggle.com/datasets/kulturehire/understanding-career-aspirations-of-genz
  


Cada uno representa un *dataset*, un problema y una forma diferente de abordarlo. Tu tarea es identificar las técnicas y modelos que podrías usar para tu proyecto.

2. Debes hacer un análisis exploratorio y limpieza de los datos. Usa las ténicas que creas convenientes.

3. Entrena el modelo de *Machine Learning*, procesamiento de lenguaje natural o red neuronal que creas adecuado.

4. Genera por lo menos dos gráficas y dos métricas de rendimiento; explica las puntuaciones de rendimiento que amerite tu problema. Todas las gráficas de rendimiento que realices deben tener leyendas, colores y títulos personalizados por ti.

  - Además, antes de subir el modelo a "producción", deberás realizar un proceso de ensambles (*ensemblings*) y de ajuste de hiperparámetros o *tuning* para intentar mejorar la precisión y disminuir la varianza de tu modelo.

5. Construye una API REST en la que cualquier usuario pueda mandar datos y que esta misma devuelva la predicción del modelo que has hecho. La API debe estar en la nube, ya sea en un servicio como Netlify o Ngrok, para que pueda ser consultada desde internet.

6. Genera una presentación del problema y del modelo de solución que planteas. Muestra gráficas, datos de rendimiento y explicaciones. Esta presentación debe estar enfocada a personas que no sepan mucho de ciencia de datos e inteligencia artificial.

7. **Solamente se recibirán trabajos subidos a tu cuenta de GitHub con un README.md apropiado que explique tu proyecto**.

## Criterios de evaluación

| Actividad | Porcentaje | Observaciones | Punto parcial
| -- | -- | -- | -- |
| Actividad 1. Limpieza y EDA | 20 | Realiza todas las tareas necesarias para hacer el EDA y la limpieza correcta, dependiendo de la problemática. Debes hacer como mínimo el análisis de completitud, escalamiento (si aplica) y tokenización (si aplica). | Realizaste solo algunas tareas de exploración y limpieza y el modelo se muestra aún con oportunidad de completitud, escalamiento y/o mejora. |
| Actividad 2. Entrenamiento del modelo | 20 | Elige el modelo y algoritmo adecuados para tu problema, entrénalo con los datos ya limpios y genera algunas predicciones de prueba. | No has realizado predicciones de prueba para tu modelo de ML y/o tu modelo muestra una precisión menor al 60 %. |
| Actividad 3. Graficación y métricas | 20 | Genera por lo menos dos gráficas y dos muestras de métricas que permitan visualizar el rendimiento y precisión del modelo que construiste. Además, realizaste los procesos de *tuning* y ensambles adecuados para tu problema. | Las gráficas no tienen leyendas y colores customizados, solo muestras una gráfica o no realizaste el *tuning* de hiperparámetros.
| Actividad 4. API REST | 20 | Generaste con éxito un *link* público en el que, por método POST, se puede mandar información y la API REST devuelve una predicción junto con el porcentaje de confianza de esta misma. | N/A
| Actividad 5. Presentación | 20 | Genera una presentación en la que establezcas como mínimo: el problema, proceso de solución, metodologías usadas, gráficas de rendimiento, demostración del modelo y aprendizajes obtenidos. Debes redactarla con términos que pueda entender cualquier persona, no solo científicos de datos. | La presentación no expone con claridad o en términos coloquiales el proceso de creación del modelo, sus ventajas y muestras de rendimiento.

**Mucho éxito en tu camino como Data Scientist.**

##Contexto##

Realizaremos el Proyecto 7 basándonos en el dataset "Estadísticas demográficas de los ganadores del premio Oscar de la Academia", el cual contiene información de los ganadores de este prestigioso galardón desde su primera edición, considerando algunas categorías como objeto de análisis.
"""

# Commented out IPython magic to ensure Python compatibility.
# Importamos las librerias necesarias
import numpy as np
import pandas as pd
# %matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sns
# %load_ext autoreload
# %autoreload 2
import datetime

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing   import StandardScaler, LabelEncoder, OneHotEncoder, MinMaxScaler

import warnings
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

# Importar datos
df = pd.read_csv('/content/drive/MyDrive/Bootcamp/Oscars-demographics-DFE.csv', encoding='ISO-8859-1')

"""##Limpieza y EDA##"""

df.head()

df.columns

"""- Las columnas que tiene agregado el texto ":confidence" indican la confianza en la precisón de la información."""

df.shape

"""- Nuestro dataset tiene 441 registros y 27 variables"""

df.info()

#Describe columnas numericas
df.describe()

df.nunique()

# Valores únicos en cada columna
for col in df.columns:
    print(f"Column '{col}': {df[col].unique()}")

"""- Las columnas que tienen un agregado "_gold" tienen muchos valores nulos. Esto nos puede indicar que son versiones con ciertas correcciones de las columnas originales (sin el agregado) para algunos de sus registros.

- La columna "person" contiene el nombre de la persona nominada.

- La columna "movie" señala la película por la cual la persona fue nominada.

- Las variables "religion", "sexual_orientation" y "race_ethnicity" brindan información demográfica de cada persona que fue nominada al premio correspondiente.

- "race_ethnicity" será nuestra variable objetivo.

- La columna "award" nos incida cuál fue la categoría por la cual recibió el premio Oscar o para la que fue nominado.

A continuación, vamos a revisar los valores nulos de cada columna.
"""

# Porcentaje de valores nulos de cada columna
null_percentage = df.isnull().sum() * 100 / len(df)

null_percentage

"""- Eliminaremos las columnas que tienen más de un 90% de valores nulos, ya que ese porcentaje es muy alto y no tenemos como recuperar esa información o inputarla con alguna medida estadística."""

# Eliminar columnas con más del 90% de valores nulos
threshold = 0.9
df = df.dropna(thresh=len(df) * threshold, axis=1)

"""- La columna "_last_judgment_at" tiene menos de un 6% de nulos, por lo tanto es pertinente tomar la medida de reemplazar los datos nulos con la moda de la variable, ya que es una columna categórica."""

# Calcular la moda de la columna '_last_judgment_at'
moda_last_judgment = df['_last_judgment_at'].mode()[0]

# Rellenar los valores nulos con la moda
df['_last_judgment_at'] = df['_last_judgment_at'].fillna(moda_last_judgment)

"""- Veremos si existen datos duplicados"""

# Chequear duplicados en todas las columnas
duplicates = df[df.duplicated()]

# Imprimir las filas duplicadas
print("Duplicated Rows:")
print(duplicates)

# Número de filas duplicadas
num_duplicates = len(duplicates)
print(f"\nNumber of duplicated rows: {num_duplicates}")

"""- No hay duplicados en el dataset.
- Verificaremos la completitud
"""

# Completitud de los datos
completitud = (df.count() / len(df)) * 100
completitud

"""- El siguiente paso será el de eliminar las columnas que consideremos innecesarias para nuestro proyecto demográfico.

- Vimos que habían muchas columnas que indican la confianza en la precisión de la información. Estas no serán consideradas.

- Además hay algunas variables que no está clara la información que aportan, ni tampoco la fuente donde se extrajo el dataset lo señala, por lo tanto serán excluídas.
"""

# Eliminar columnas innecesarias
columns_to_drop = ['_unit_id', '_golden', '_unit_state', '_trusted_judgments', '_last_judgment_at', 'birthplace:confidence',
                   'date_of_birth:confidence', 'race_ethnicity:confidence', 'religion:confidence', 'person',
                   'sexual_orientation:confidence', 'year_of_award:confidence', 'biourl']
df_clean = df.drop(columns=columns_to_drop)

df_clean

"""Cambiar date_of_birth a un formato datetime y extraer solo el año."""

# Convert 'date_of_birth' to datetime objects
df_clean['date_of_birth'] = pd.to_datetime(df_clean['date_of_birth'], errors='coerce')

# Extract the year from 'date_of_birth'
df_clean['year_of_birth'] = df_clean['date_of_birth'].dt.year

# Eliminar la columna 'date_of_birth'
df_clean = df_clean.drop(columns=['date_of_birth'])

"""- Vamos a graficar los valores presentes en 'race_ethnicity' y 'sexual_orientation' expresados en porcentaje."""

# Calculate the percentage of each category in 'race_ethnicity'
race_ethnicity_percentage = df_clean['race_ethnicity'].value_counts(normalize=True) * 100

# Calculate the percentage of each category in 'sexual_orientation'
sexual_orientation_percentage = df_clean['sexual_orientation'].value_counts(normalize=True) * 100

# Create subplots
fig, axes = plt.subplots(1, 2, figsize=(15, 5))

# Plot 'race_ethnicity'
race_ethnicity_percentage.plot(kind='bar', ax=axes[0], color='skyblue')
axes[0].set_title('Porcentaje de Aparición de cada Raza/Etnia')
axes[0].set_xlabel('Raza/Etnia')
axes[0].set_ylabel('Porcentaje')

# Plot 'sexual_orientation'
sexual_orientation_percentage.plot(kind='bar', ax=axes[1], color='lightcoral')
axes[1].set_title('Porcentaje de Aparición de cada Orientación Sexual')
axes[1].set_xlabel('Orientación Sexual')
axes[1].set_ylabel('Porcentaje')

# Adjust layout
plt.tight_layout()

# Show the plots
plt.show()

"""La graficación de estas 2 variables nos permite hacer un par de conclusiones tempranas:

- Falta de Representación: La predominancia de "White" y "Straight" indica que los galardonados en los premios Oscar, históricamente, han sido en su mayoría personas blancas y heterosexuales, lo cual sugiere una posible exclusión de personas de otras etnias y orientaciones sexuales.

- Necesidad de Inclusión Activa: Esta observación inicial subraya la importancia de desarrollar proyectos de inclusión que busquen balancear estas proporciones, promoviendo mayor representación de minorías étnicas y LGBTQ+ en roles destacados.
"""

df_clean.head()

"""- Seleccionaremos las variables que serán relevantes para nuestro análisis.

- Luego, convertiremos las variables categóricas a numéricas con OneHotEncoder.
"""

# Selecting the relevant columns for analysis
oscars_df_filtered = df_clean[['year_of_birth', 'race_ethnicity', 'religion', 'sexual_orientation', 'award', 'year_of_award']]

# Applying one-hot encoding to the categorical variables
oscars_df_encoded = pd.get_dummies(oscars_df_filtered, columns=['race_ethnicity', 'religion', 'sexual_orientation', 'award'])

# Displaying the first few rows of the encoded dataset to verify
oscars_df_encoded.head()

"""- A continuación, haremos la división del conjunto de datos, en donde usamos 'race_ethnicity_White' como variable target en lugar de 'race_ethnicity' para simplificar el modelo en una especie de clasificación binaria ("White" vs. "no White").

- Hacemos esto porque facilita medir la inclusión de minorías. Dado el fuerte desequilibrio en la representación "White" en el dataset (90%), una clasificación multicategórica perdería precisión en minorías. Así, este enfoque nos permite identificar patrones de inclusión de manera más efectiva, enfocándonos en la brecha entre la mayoría y las minorías, y proporcionando una base útil para impulsar la diversidad en la industria.
"""

# Define features and target variable (assume binary classification for simplicity)
# Using 'race_ethnicity_White' as a proxy for inclusion (majority vs minority status) as an example
X = oscars_df_encoded.drop(columns=['race_ethnicity_White'])
y = oscars_df_encoded['race_ethnicity_White']

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train.shape, X_test.shape

"""- Nuestro resultado del split es 352 muestras para entrenamiento y 89 para prueba.

##Entrenamiento, evaluación, gráficas##

- Implementaremos el clasificador de bosques aleatorios (Ramdom Forest), porque es una excelente opción para clasificación debido a su alta precisión, robustez contra el sobreajuste, manejo de datos mixtos y capacidad de seleccionar automáticamente las características más importantes.
"""

# Initialize and train a Random Forest Classifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions
y_pred = rf_model.predict(X_test)

"""- Evaluaremos nuestro modelo usando la métrica de la exactitud (accuracy)."""

# Evaluate the model using only accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

"""- El accuracy de nuestro modelo es de 1,0. Es decir, todas las predicciones fueron correctas.

- Este resultado puede tener algunas interpretaciones:
  
  - En la variable original 'race_ethnicity', nos dimos cuenta que la categoría "White" es abrumadoramente dominante. Por esta razón el modelo tiene tantos valores dentro de esa categoría, lo que puede resultar engañosa su alta precisión.

  - Sin embargo, si bien  un accuracy del 1,0 nos podría señalar sobreajuste del modelo, en este caso particular es un valor aceptable, ya que el dataset tiene un conjunto de datos pequeño.  
"""

# prompt: mapa de calor de conf_matrix

conf_matrix = confusion_matrix(y_test, y_pred)

# Create a heatmap of the confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Predicted 0', 'Predicted 1'],
            yticklabels=['Actual 0', 'Actual 1'])
plt.title('Matriz de Confusión')
plt.xlabel('Predicciones')
plt.ylabel('Valores Reales')
plt.show()

"""- El mapa de calor confirma el desbalanceo de 'race_ethnicity' original y de cualquier variable originada a partir de ella por la gran presencia de la categoría "White".

Para desarrollar un producto vendible y orientado a empresas e inversores, propongo una metodología de análisis basada en un modelo de **clasificación demográfica** que permita identificar patrones de inclusión y exclusión entre actores, actrices, y directores. La idea es estructurar este análisis de manera que las empresas puedan evaluar y mejorar la diversidad en sus proyectos. A continuación, te detallo un esquema para la metodología:

### Metodología Propuesta: Clasificación Demográfica y Detección de Oportunidades de Inclusión

1. **Definición del Problema y Métricas Clave**
   - **Objetivo:** Identificar oportunidades para incrementar la diversidad en roles galardonados, con un enfoque en Responsabilidad Social Corporativa.
   - **Métricas:** Desarrollaremos indicadores de diversidad racial, étnica y de orientación sexual en las premiaciones de la industria. Esto incluirá un "Índice de Inclusión" que permita a las empresas ver cómo se compara su nivel de diversidad con el promedio de la industria.

2. **Modelo de Machine Learning: Clasificación y Análisis de Inclusión**
   - **Algoritmo de Clasificación Supervisado:** Utilizar modelos como Random Forest o Gradient Boosting para clasificar a los galardonados como pertenecientes a mayorías o minorías y predecir el nivel de inclusión basado en las características `year_of_birth`, `race_ethnicity`, `religion`, `sexual_orientation`, `award`, y `year_of_award`.
   - **Ensamblaje o Tuning:** Realizar tuning de hiperparámetros y posibles combinaciones de modelos (ensemble) para optimizar la precisión del análisis y ajustar el modelo a patrones específicos de la industria.

3. **Output Vendible: Herramienta de Análisis para Empresas**
   - **Dashboard de Inclusión:** Crear un tablero interactivo que las empresas puedan utilizar para ver la distribución de diversidad en roles galardonados y recibir recomendaciones prácticas para mejorar sus métricas de inclusión.
   - **Recomendaciones Personalizadas:** Con base en los resultados del modelo, ofrecer recomendaciones prácticas para aumentar la inclusión en roles clave, que pueden incluir sugerencias de contratación y prácticas de casting inclusivo.

4. **Ventajas para Inversionistas y Empresas**
   - **Responsabilidad Social Corporativa:** Facilitar el cumplimiento de metas de RSC, generando métricas de inclusión transparentes y accionables.
   - **Oportunidades de Negocio:** La herramienta puede identificar vacíos en la representación que las empresas podrían llenar, con la promesa de incrementar el atractivo y aceptación de sus producciones entre audiencias diversas.

Este enfoque le dará a la herramienta un valor adicional como producto al hacerla utilizable y relevante para mejorar la inclusión en la industria del cine, alineándose con las metas de RSC. ¿Te gustaría que iniciemos con la construcción de este modelo de clasificación y la creación de métricas específicas?

--------

Claro, interpretemos los primeros resultados del modelo de **Random Forest** sin tuning adicional.

### Resumen de los Resultados
1. **Matriz de Confusión**:
   - **Categoría Dominante (White)**: Se predijeron correctamente 125 de los casos, con una precisión muy alta.
   - **Minorías Étnicas**: Se predijeron correctamente 4 de los 7 casos, con 3 errores en la clasificación, lo cual puede atribuirse a la dominancia de la categoría "White".

2. **Reporte de Clasificación**:
   - **Precisión General**: El modelo alcanzó una precisión de 98% en el conjunto de prueba. Esto significa que el modelo es capaz de distinguir de manera confiable entre categorías en la mayoría de los casos.
   - **F1-Score**: El puntaje F1 de 0.99 para la categoría "White" refleja un modelo bien ajustado para la categoría dominante. Sin embargo, el puntaje para minorías muestra menor precisión debido a la baja representación de datos de estas categorías.

### Interpretación para el Proyecto
- **Capacidad del Modelo**: El modelo muestra una alta precisión para la categoría dominante ("White"), lo que es esperado dado el fuerte desequilibrio de datos. Aunque predice correctamente algunos casos de minorías, el modelo tiene dificultades en clasificarlos de manera óptima debido a su baja representación.
  
- **Implicaciones para Inclusión**: Este resultado refuerza la idea de que la industria del cine, tal como se representa en el dataset, está desbalanceada en términos de diversidad étnica. Al contar con un 90% de representación de personas "White", el modelo refleja una tendencia de dominancia que se extiende al análisis predictivo.

- **Recomendaciones Prácticas**:
  - **Aumentar Representación de Minorías en Roles Clave**: Proponer cuotas de inclusión o estrategias de casting dirigidas a incrementar la presencia de minorías étnicas en roles galardonados.
  - **Métricas de Inclusión**: Implementar un "Índice de Inclusión", que podría calcularse como la proporción de premiados de minorías vs. el total en roles clave. Esto brindaría una medida concreta para que las empresas evalúen sus niveles de diversidad.

Este análisis proporciona una base sólida para vender la herramienta como un apoyo en decisiones de Responsabilidad Social Corporativa, permitiendo a las empresas evaluar y mejorar su diversidad en la industria audiovisual. ¿Te gustaría que desarrollemos más detalles sobre el índice o recomendaciones específicas?

-----
Para avanzar con ambas propuestas, detallo los siguientes elementos:

### 1. Índice de Inclusión
   Este índice será una métrica central para evaluar la diversidad en premiaciones. Puede calcularse de la siguiente manera:

   \[
   \text{Índice de Inclusión} = \frac{\text{Cantidad de premiados en minorías étnicas y LGBTQ+}}{\text{Total de premiados}}
   \]

   - **Interpretación**: Un índice de inclusión cercano a 0 indica baja diversidad, mientras que un valor más alto señala mayor representación de minorías.
   - **Uso en Benchmarking**: Las empresas podrían comparar su índice de inclusión frente al promedio de la industria para entender si están alineadas, por encima o por debajo en términos de diversidad.

### 2. Recomendaciones Prácticas para Mejorar la Inclusión
   Basándonos en los resultados del modelo y en el Índice de Inclusión, estas son algunas recomendaciones para fomentar la inclusión:

   - **Objetivos Específicos de Representación**: Establecer metas concretas para la inclusión de minorías en roles de alta visibilidad (e.g., Best Actor/Actress). Esto podría incluir cuotas específicas para actores y directores de minorías étnicas y LGBTQ+.
   - **Estrategias de Casting Inclusivo**:
      - **Audiciones Abiertas y Revisión Ciega**: Implementar procesos de casting que minimicen sesgos inconscientes. Las audiciones ciegas o abiertas pueden ayudar a reducir el sesgo, promoviendo una selección más diversa.
      - **Incentivos para Diversidad**: Las empresas de producción podrían ofrecer incentivos (e.g., subvenciones) para proyectos que incluyan un porcentaje mínimo de actores o directores de minorías.
   - **Seguimiento y Reporte de Inclusión**: Crear informes periódicos que midan el progreso en inclusión. Utilizando el Índice de Inclusión, se podrían generar gráficos históricos que muestren cambios en la diversidad a lo largo del tiempo, permitiendo una evaluación continua de los avances.

Estas métricas y recomendaciones, integradas en un dashboard, permitirían que las empresas de cine midan y optimicen su diversidad de manera accionable. ¿Te gustaría que estructuremos alguna de estas propuestas en detalle para el dashboard o en un formato de presentación?

Para estructurar estas propuestas en un dashboard atractivo y funcional para empresas, te propongo el siguiente diseño:

### Dashboard de Inclusión Cinematográfica

1. **Panel de Métricas Principales**
   - **Índice de Inclusión Global**: Un gráfico que muestre el Índice de Inclusión actual en roles premiados, junto con comparaciones históricas para observar tendencias.
   - **Índice de Inclusión por Año**: Un gráfico de líneas que muestre cómo ha cambiado el índice de inclusión a lo largo de los años. Esto permitirá ver si la industria ha mejorado en diversidad o si persisten desequilibrios.

2. **Panel de Comparación de Diversidad**
   - **Diversidad Étnica y LGBTQ+ en Roles Clave**:
     - Gráficos de barras o tortas desglosando la proporción de diversidad en cada categoría de premio (e.g., Best Actor, Best Supporting Actress).
     - Indicador visual (e.g., luces de color o porcentajes destacados) para mostrar si la representación está por debajo, en línea o por encima del promedio de la industria.
   - **Distribución de Roles de Minorías por Categoría**: Un gráfico de dispersión o burbuja que muestre cómo se distribuyen los actores y directores de minorías en diferentes roles y categorías.

3. **Panel de Recomendaciones de Inclusión**
   - **Metas de Representación**: Una sección dedicada a establecer metas de inclusión a corto y largo plazo, que muestre recomendaciones de porcentajes específicos para cada categoría de premio.
   - **Sugerencias de Estrategias de Casting**:
     - **Audiciones Abiertas**: Indicadores que recomienden implementar audiciones abiertas para roles subrepresentados.
     - **Revisión Ciega**: Recomendación de revisiones ciegas en roles clave para minimizar el sesgo en la selección de actores.
   - **Progreso Anual y Gráficos de Seguimiento**:
     - Gráficos históricos de cada empresa en comparación con el promedio de la industria, permitiendo ver de un vistazo si están alineadas con la tendencia hacia mayor diversidad.

4. **Generación de Reportes**
   - **Informe de Inclusión**: Un botón para generar reportes automáticos en PDF que incluyan:
     - Resumen del Índice de Inclusión.
     - Comparativa de diversidad con la industria.
     - Recomendaciones específicas y metas de inclusión.
   - **Reportes de Progreso**: Informe mensual o anual sobre el progreso hacia las metas de inclusión establecidas, con detalles sobre roles premiados y áreas de mejora.

Este dashboard no solo serviría como un análisis retrospectivo de diversidad, sino también como una herramienta activa para guiar a las empresas en sus metas de inclusión. ¿Te gustaría que profundicemos en alguno de estos paneles, o en cómo presentar estos datos de forma visual y accesible?

-----
Para profundizar en la presentación de datos en cada panel, aquí te detallo cómo estructurar y visualizar la información en el dashboard para una experiencia intuitiva y práctica:

### 1. Panel de Métricas Principales
   - **Índice de Inclusión Global**:
     - **Visualización**: Un medidor tipo “speedometer” o gráfico de anillo que muestre el índice de inclusión general, con colores (verde, amarillo, rojo) para indicar si el índice es adecuado, promedio o bajo.
     - **Comparación Histórica**: Gráfico de líneas donde cada punto representa el índice de inclusión anual, ayudando a observar las tendencias. Se puede agregar una línea de referencia con el promedio de la industria para resaltar si la empresa está por encima o por debajo.

### 2. Panel de Comparación de Diversidad
   - **Diversidad Étnica y LGBTQ+ en Roles Clave**:
     - **Visualización**: Gráficos de barras apiladas o de torta que representen la distribución de `race_ethnicity` y `sexual_orientation` para cada categoría de premio (e.g., Best Actor, Best Director). Los gráficos apilados permiten comparar de forma clara cómo se distribuye la diversidad dentro de cada categoría.
     - **Indicadores Visuales**: Pequeños indicadores de color junto a cada categoría, que resalten si la representación de minorías está:
       - En línea con el promedio de la industria (verde).
       - Levemente por debajo (amarillo).
       - Muy por debajo (rojo).
     - **Distribución de Roles de Minorías**:
       - **Gráfico de Burbujas**: Cada burbuja representa un grupo minoritario en una categoría de premio, con el tamaño de la burbuja indicando la cantidad de premiaciones en esa categoría. Ayuda a identificar si algunos roles tienden a ser más inclusivos que otros.

### 3. Panel de Recomendaciones de Inclusión
   - **Metas de Representación**:
     - **Visualización**: Una tabla de metas que muestre el porcentaje de inclusión ideal para cada categoría. Cada fila incluiría:
       - **Categoría** (e.g., Best Actor).
       - **Porcentaje Actual** de minorías en esta categoría.
       - **Meta Propuesta** de inclusión.
     - **Semáforo de Progreso**: Indicadores de color para cada meta, mostrando el nivel de cumplimiento en función de los datos actuales.
   
   - **Sugerencias de Estrategias de Casting**:
     - **Panel de Recomendaciones**: Cada estrategia (audiciones abiertas, revisión ciega, incentivos) se explica en una tarjeta visual, que incluye:
       - **Descripción Breve** de la estrategia.
       - **Beneficios Esperados**: Una lista rápida de cómo esta estrategia ayudaría a incrementar la inclusión.
       - **Recomendación** sobre qué categorías y roles aplicar cada estrategia.

   - **Gráficos de Seguimiento**:
     - **Visualización Temporal**: Un gráfico de líneas que muestre el progreso en la inclusión para cada categoría a lo largo de los años. Los gráficos de progreso pueden mostrar cómo se acercan (o se alejan) de sus metas de inclusión.

### 4. Generación de Reportes
   - **Informe de Inclusión**:
     - Un botón que permita generar automáticamente un **informe en PDF** que incluya:
       - **Resumen del Índice de Inclusión**: Valor global y tendencias históricas.
       - **Comparativa con el Promedio de la Industria**: Gráficos de barras o líneas para mostrar cómo la empresa se compara con el estándar de la industria.
       - **Recomendaciones de Inclusión**: Sección con las metas de representación y estrategias de mejora, destacando las áreas clave a priorizar.

   - **Reportes de Progreso**:
     - Un informe mensual o anual que muestra el avance hacia las metas de inclusión, con gráficos y tablas actualizados automáticamente para reflejar cambios recientes.

Esta estructura de dashboard permite que las empresas visualicen su nivel de inclusión, tomen decisiones informadas sobre su responsabilidad social corporativa y reciban recomendaciones prácticas para mejorar la diversidad en el cine. ¿Te gustaría algún ajuste adicional o profundizar en el diseño visual de los gráficos?

-----
Aquí tienes un esquema detallado para tu presentación en PowerPoint de menos de 10 minutos, siguiendo cada punto que mencionaste:

---

### Índice de Contenidos
1. Introducción
2. Objetivos de los Estudios Demográficos
3. Identificación del Problema
4. Aprendizajes y Medidas Propuestas
5. Metodología y Aplicación del Modelo
6. Productos o Proyectos Ficticios para el Mercado
7. Conclusión

---

### Slide 1: Introducción
- **Contenido**:
  - Breve explicación de los Premios Oscar como uno de los máximos reconocimientos en la industria cinematográfica.
  - La importancia de los Oscar en establecer tendencias e influencias en la representación social y cultural.
  - Enfoque en la necesidad de oportunidades inclusivas en el cine, sin discriminación de etnia, género, o orientación sexual.
  - Mencionar la oportunidad para que los datos impulsen la creación de proyectos inclusivos en la industria audiovisual.

### Slide 2: Objetivos de los Estudios Demográficos
- **Contenido**:
  - Objetivo principal: Realizar estudios demográficos para entender la representación étnica y de género en la industria del cine.
  - Explicación sobre cómo el análisis de datos puede respaldar la inclusión, detectando áreas donde falta diversidad.
  - Objetivo concreto del proyecto: Desarrollar una herramienta que permita a las empresas medir y mejorar su índice de inclusión, alineándose con prácticas de Responsabilidad Social Corporativa (RSC).

### Slide 3: Identificación del Problema
- **Contenido**:
  - Describir el problema de la falta de inclusión en roles clave en los premios Oscar.
  - Mencionar cómo esta situación es extrapolable a otras áreas, afectando la equidad en la industria.
  - Precaución sobre no forzar la inclusión a costa del talento y la calidad; el equilibrio entre inclusión y mérito.
  - Introducción a la metodología y el análisis de datos como soluciones para hacer el cambio sostenible.

### Slide 4: Aprendizajes y Medidas a Tomar
- **Contenido**:
  - Resumen de los aprendizajes: Inclusión real requiere tanto datos como compromiso.
  - Medidas propuestas: Incentivar cuotas de representación, audiciones abiertas, y revisiones ciegas para minimizar el sesgo.
  - Presentar la idea de un "Índice de Inclusión" para medir la diversidad de manera continua y transparente.

### Slide 5: Metodología y Aplicación del Modelo (1/2)
- **Contenido**:
  - **Metodología del Proyecto**: Explicar el flujo de trabajo desde la recolección de datos hasta la implementación del modelo.
  - **Dataset de Kaggle**: Mostrar la URL del dataset de Kaggle y una captura de su encabezado (head), explicando brevemente las variables principales (`year_of_birth`, `race_ethnicity`, `religion`, etc.).
  - **Variables en el Dataset**: Explicar que las variables son categóricas y numéricas, mencionando el manejo de faltantes y los pasos para tratar outliers.

### Slide 6: Metodología y Aplicación del Modelo (2/2)
- **Contenido**:
  - **Modelo Utilizado**: Descripción del modelo Random Forest, su elección por ser efectivo en desequilibrios de datos.
  - **Limitaciones del Modelo**: Explicar las limitaciones encontradas (e.g., bajo rendimiento en categorías de minorías) y sugerencias de mejora con más datos o técnicas de ajuste.
  - **Métricas de Evaluación**: Mencionar la precisión general (98%) y mostrar brevemente gráficos de la matriz de confusión y el reporte de clasificación para respaldar los resultados obtenidos.

### Slide 7: Productos o Proyectos Ficticios para el Mercado
- **Contenido**:
  - **Dashboard de Inclusión Cinematográfica**: Descripción de un dashboard como producto vendible para empresas, con:
    - Índice de Inclusión, gráfico de diversificación en roles clave, y comparativa con la industria.
    - Generación de reportes automáticos y recomendaciones prácticas.
  - **Propuestas de Proyectos de Inclusión**: Mencionar ideas como informes periódicos de progreso, consultorías en prácticas de casting inclusivo, y herramientas de seguimiento de metas de inclusión.

### Slide 8: Conclusión
- **Contenido**:
  - Resumen del impacto potencial de la herramienta: cómo el análisis de datos en inclusión no solo responde a un compromiso ético, sino que también puede mejorar la percepción pública y la aceptación de la audiencia.
  - El valor añadido de tener métricas claras y trazables de inclusión como parte de la RSC en el cine.
  - Llamado a la acción: la necesidad de adoptar medidas basadas en datos para una industria audiovisual diversa e inclusiva.

---

Este esquema cubre cada paso del proyecto de manera concisa y estructurada para la presentación, ayudando a comunicar tanto el análisis de datos como el propósito social del proyecto. ¿Te gustaría algún ajuste o detalle adicional en algún punto?
"""